% Generated by IEEEtran.bst, version: 1.13 (2008/09/30)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{hinton2012deep}
G.~Hinton, L.~Deng, D.~Yu, G.~E. Dahl, A.-r. Mohamed, N.~Jaitly, A.~Senior,
  V.~Vanhoucke, P.~Nguyen, T.~N. Sainath, and B.~Kingsbury, ``Deep neural
  networks for acoustic modeling in speech recognition: The shared views of
  four research groups,'' \emph{IEEE Signal Processing Magazine}, vol.~29,
  no.~6, pp. 82--97, 2012.

\bibitem{ragni2016multi}
A.~Ragni, E.~Dakin, X.~Chen, M.~J. Gales, and K.~M. Knill, ``Multi-language
  neural network language models.'' in \emph{Proc. INTERSPEECH}, 2016, pp.
  3042--3046.

\bibitem{Saon2017}
G.~Saon, G.~Kurata, T.~Sercu, K.~Audhkhasi, S.~Thomas, D.~Dimitriadis, X.~Cui,
  B.~Ramabhadran, M.~Picheny, L.-L. Lim, B.~Roomi, and P.~Hall, ``English
  conversational telephone speech recognition by humans and machines,'' in
  \emph{Proc. INTERSPEECH}, 2017, pp. 132--136.

\bibitem{Hori2017}
T.~Hori, S.~Watanabe, Y.~Zhang, and W.~Chan, ``Advances in joint
  {CTC}-attention based end-to-end speech recognition with a deep cnn encoder
  and {RNN-LM},'' in \emph{Proc. INTERSPEECH}, 2017, pp. 949--953.

\bibitem{shibata2017composite}
H.~Shibata, T.~Kato, T.~Shinozaki, and S.~Watanabe, ``Composite embedding
  systems for zerospeech2017 track 1,'' in \emph{Proc. ASRU}, 2017, pp.
  747--753.

\bibitem{dunbar2017zero}
E.~Dunbar, X.-N. Cao, J.~Benjumea, J.~Karadayi, M.~Bernard, L.~Besacier,
  X.~Anguera, and E.~Dupoux, ``The zero resource speech challenge 2017,'' in
  \emph{Proc. ASRU}, 2017, pp. 323--330.

\bibitem{glass2012towards}
J.~Glass, ``Towards unsupervised speech processing,'' in \emph{Proc. ISSPA},
  2012, pp. 1--4.

\bibitem{kamper2015fully}
H.~Kamper, A.~Jansen, and S.~Goldwater, ``Fully unsupervised small-vocabulary
  speech recognition using a segmental bayesian model,'' in \emph{Proc.
  INTERSPEECH}, 2015, pp. 678--682.

\bibitem{thiolliere2015hybrid}
R.~Thiolli\`{e}re, E.~Dunbar, G.~Synnaeve, M.~Versteegh, and E.~Dupoux, ``A
  hybrid dynamic time warping-deep neural network architecture for unsupervised
  acoustic modeling,'' in \emph{Proc. INTERSPEECH}, 2015, pp. 3179--3183.

\bibitem{versteegh2015zero}
M.~Versteegh, R.~Thiolli\`{e}re, T.~Schatz, X.-N. Cao, X.~Anguera, A.~Jansen,
  and E.~Dupoux, ``The zero resource speech challenge 2015.'' in \emph{Proc.
  INTERSPEECH}, 2015, pp. 3169--3173.

\bibitem{Chen+2016}
H.~Chen, C.-C. Leung, L.~Xie, B.~Ma, and H.~Li, ``Unsupervised bottleneck
  features for low-resource query-by-example spoken term detection,'' in
  \emph{INTERSPEECH}, 2016, pp. 923--927.

\bibitem{yuan2017extracting}
Y.~Yuan, C.-C. Leung, L.~Xie, H.~Chen, B.~Ma, and H.~Li, ``Extracting
  bottleneck features and word-like pairs from untranscribed speech for feature
  representations,'' in \emph{Proc. ASRU}, 2017, pp. 734--739.

\bibitem{chung2015iterative}
C.-T. Chung, C.-Y. Tsai, H.-H. Lu, C.-H. Liu, H.-y. Lee, and L.-s. Lee, ``An
  iterative deep learning framework for unsupervised discovery of speech
  features and linguistic units with applications on spoken term detection,''
  in \emph{Proc. ASRU}, 2015, pp. 245--251.

\bibitem{heck2017feature}
M.~Heck, S.~Sakti, and S.~Nakamura, ``Feature optimized {DPGMM} clustering for
  unsupervised subword modeling: A contribution to zerospeech 2017,'' in
  \emph{Proc. ASRU}, 2017, pp. 740--746.

\bibitem{ansari2017deep}
T.~K. Ansari, R.~Kumar, S.~Singh, and S.~Ganapathy, ``Deep learning methods for
  unsupervised acoustic modeling - {LEAP} submission to zerospeech challenge
  2017,'' in \emph{Proc. ASRU}, 2017, pp. 754--761.

\bibitem{chen2017multilingual}
H.~Chen, C.-C. Leung, L.~Xie, B.~Ma, and H.~Li, ``Multilingual bottle-neck
  feature learning from untranscribed speech,'' in \emph{Proc. ASRU}, 2017, pp.
  727--733.

\bibitem{anastasakos1997speaker}
T.~Anastasakos, J.~McDonough, and J.~Makhoul, ``Speaker adaptive training: A
  maximum likelihood approach to speaker normalization,'' in \emph{Proc.
  ICASSP}, vol.~2, 1997, pp. 1043--1046.

\bibitem{miao2015speaker}
Y.~Miao, H.~Zhang, and F.~Metze, ``Speaker adaptive training of deep neural
  network acoustic models using i-vectors,'' \emph{IEEE/ACM Trans. ASLP},
  vol.~23, no.~11, pp. 1938--1949, 2015.

\bibitem{Cui2017}
X.~Cui, V.~Goel, and G.~Saon, ``Embedding-based speaker adaptive training of
  deep neural networks,'' in \emph{Proc. INTERSPEECH}, 2017, pp. 122--126.

\bibitem{gales1998maximum}
M.~J. Gales, ``Maximum likelihood linear transformations for {HMM}-based speech
  recognition,'' \emph{Computer speech \& language}, vol.~12, no.~2, pp.
  75--98, 1998.

\bibitem{li2010comparison}
B.~Li and K.~C. Sim, ``Comparison of discriminative input and output
  transformations for speaker adaptation in the hybrid {NN/HMM} systems,'' in
  \emph{Proc. INTERSPEECH}, 2010, pp. 526--529.

\bibitem{saon2013speaker}
G.~Saon, H.~Soltau, D.~Nahamoo, and M.~Picheny, ``Speaker adaptation of neural
  network acoustic models using i-vectors,'' in \emph{Proc. ASRU}, 2013, pp.
  55--59.

\bibitem{xue2014fast}
S.~Xue, O.~Abdel-Hamid, H.~Jiang, L.~Dai, and Q.~Liu, ``Fast adaptation of deep
  neural network based on discriminant codes for speech recognition,''
  \emph{IEEE/ACM Trans. ASLP}, vol.~22, no.~12, pp. 1713--1725, 2014.

\bibitem{seltzer2013investigation}
M.~L. Seltzer, D.~Yu, and Y.~Wang, ``An investigation of deep neural networks
  for noise robust speech recognition,'' in \emph{Proc. ICASSP}, 2013, pp.
  7398--7402.

\bibitem{Xie2017}
X.~Xie, X.~Liu, T.~Lee, and L.~Wang, ``{RNN-LDA} clustering for feature based
  {DNN} adaptation,'' in \emph{Proc. INTERSPEECH}, 2017, pp. 2396--2400.

\bibitem{chang2013parallel}
J.~Chang and J.~W. Fisher~III, ``Parallel sampling of {DP} mixture models using
  sub-cluster splits,'' in \emph{Advances in Neural Information Processing
  Systems}, 2013, pp. 620--628.

\bibitem{chen2015parallel}
H.~Chen, C.-C. Leung, L.~Xie, B.~Ma, and H.~Li, ``Parallel inference of
  dirichlet process gaussian mixture models for unsupervised acoustic modeling:
  A feasibility study,'' in \emph{Proc. INTERSPEECH}, 2015, pp. 3189--3193.

\bibitem{paul1992design}
D.~B. Paul and J.~M. Baker, ``The design for the wall street journal-based
  {CSR} corpus,'' in \emph{Proc. workshop on Speech and Natural
  Language}.\hskip 1em plus 0.5em minus 0.4em\relax Association for
  Computational Linguistics, 1992, pp. 357--362.

\bibitem{LeeLoChingEtAl2002}
T.~Lee, W.~K. Lo, P.~C. Ching, and H.~Meng, ``Spoken language resources for
  cantonese speech processing,'' \emph{Speech Communication}, vol.~36, no.~3,
  pp. 327--342, 2002.

\bibitem{ansari2017unsupervised}
T.~K. Ansari, R.~Kumar, S.~Singh, S.~Ganapathy, and S.~Devi, ``Unsupervised
  {HMM} posteriograms for language independent acoustic modeling in zero
  resource conditions,'' in \emph{Proc. ASRU}, 2017, pp. 762--768.

\bibitem{kim2004using}
D.~Kim, S.~Umesh, M.~J. Gales, T.~Hain, and P.~Woodland, ``Using {VTLN} for
  broadcast news transcription,'' in \emph{Proc. ICSLP}, 2004.

\bibitem{haeb1992linear}
R.~Haeb-Umbach and H.~Ney, ``Linear discriminant analysis for improved large
  vocabulary continuous speech recognition,'' in \emph{Proc. ICASSP}, vol.~1,
  1992, pp. 13--16.

\bibitem{gales1999semi}
M.~J. Gales, ``Semi-tied covariance matrices for hidden markov models,''
  \emph{IEEE Trans. SAP}, vol.~7, no.~3, pp. 272--281, 1999.

\bibitem{povey2012basis}
D.~Povey and K.~Yao, ``A basis representation of constrained {MLLR} transforms
  for robust adaptation,'' \emph{Computer Speech \& Language}, vol.~26, no.~1,
  pp. 35--51, 2012.

\bibitem{renshaw2015comparison}
D.~Renshaw, H.~Kamper, A.~Jansen, and S.~Goldwater, ``A comparison of neural
  network methods for unsupervised representation learning on the zero resource
  speech challenge,'' in \emph{Proc. INTERSPEECH}, 2015, pp. 3199--3203.

\bibitem{kamper2014unsupervised}
H.~Kamper, A.~Jansen, S.~King, and S.~Goldwater, ``Unsupervised lexical
  clustering of speech segments using fixed-dimensional acoustic embeddings,''
  in \emph{Proc. SLT}, 2014, pp. 100--105.

\bibitem{Heck+2016}
M.~Heck, S.~Sakti, and S.~Nakamura, ``Supervised learning of acoustic models in
  a zero resource setting to improve {DPGMM} clustering,'' in \emph{Proc.
  INTERSPEECH}, 2016, pp. 1310--1314.

\bibitem{grezl2009investigation}
F.~Gr{\'e}zl, M.~Karafi{\'a}t, and L.~Burget, ``Investigation into bottle-neck
  features for meeting speech recognition,'' in \emph{Proc. INTERSPEECH}, 2009,
  pp. 2947--2950.

\bibitem{caruana1998multitask}
R.~Caruana, ``Multitask learning,'' in \emph{Learning to learn}.\hskip 1em plus
  0.5em minus 0.4em\relax Springer, 1998, pp. 95--133.

\bibitem{povey2011kaldi}
D.~Povey, A.~Ghoshal, G.~Boulianne, L.~Burget, O.~Glembek, N.~Goel,
  M.~Hannemann, P.~Motlicek, Y.~Qian, P.~Schwarz \emph{et~al.}, ``The kaldi
  speech recognition toolkit,'' in \emph{Proc. ASRU}, 2011.

\bibitem{Stolcke02srilm--}
A.~Stolcke, ``{SRILM} -- an extensible language modeling toolkit,'' in
  \emph{Proc. ICSLP}, 2002, pp. 901--904.

\end{thebibliography}
